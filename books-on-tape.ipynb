{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Literary authors have a wide variety of styles, contexts, and characters they describe in their works. Many of these styles are repeatable, demonstrating identifiable patterns across their bodies of work. These styles can evolve over time, changing as the lives of the authors themselves evolve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Initialize Your Resources\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting. If you don't specify a bucket, SageMaker SDK will create a default bucket following a pre-defined naming convention in the same region.\n",
    "The IAM role ARN used to give SageMaker access to your data. It can be fetched using the get_execution_role method from sagemaker python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::023375022819:role/service-role/AmazonSageMaker-ExecutionRole-20181029T121824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-023375022819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-023375022819\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role) # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = sess.default_bucket() # Replace with your own bucket name if needed\n",
    "print(bucket)\n",
    "prefix = 'blazingtext/supervised'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation\n",
    "\n",
    "The data has been processed from MP3 -> Transcribe -> JSON -> CSV that we want to train the text classification model. BlazingText expects a single preprocessed text file with space separated tokens and each line of the file should contain a single sentence and the corresponding label(s) prefixed by \"__label__\".\n",
    "\n",
    "Lets train the text classification model by Jane Austen and Charles Dickens. We will be Training the BlazingText model for supervised text classification.\n",
    "\n",
    "Need to determine what length of document you use to train the model. This means that you will need to format the Transcribe results into a both data type that BlazingText can read, and a data type that intuitively lends itself well to the author classification problem. We will do this sentence-by-sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the bucket contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientist.48.book.on.tape/authors/\n",
      "scientist.48.book.on.tape/mp3Audio/\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/love_freindship_cs_librivox_64kb_mp3/love-freindship_1_austen_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/love_freindship_cs_librivox_64kb_mp3/love-freindship_2_austen_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/love_freindship_cs_librivox_64kb_mp3/love-freindship_3_austen_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_01-04_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_05-06_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_07-08_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_09-10_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_11-13_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_14-15_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_16-17_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_19-20_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_21-22_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_23-24_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_25-26_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_27-28_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_29-30_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_31-32_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_33-34_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_35_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_36-37_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_38-40_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_41_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_42_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_43_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_44-45_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_46_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_47-48_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_49_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_50-51_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_52_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_53-54_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_55_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_56_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_57_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_58_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_59_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Austen/solo_pride_librivox_64kb_mp3/prideandprejudice_60-61_austen_apc_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_01_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_03_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_04_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_05_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_06_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_07_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_08_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_09_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_10_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_12_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_13_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_14_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_15_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_16_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_17_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_18_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_19_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_20_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_21_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_22_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_23_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_24_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_25_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_26_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_27_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_28_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_29_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_31_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_32_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_33_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_34_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_35_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_36_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_37_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_38_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_39_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_40_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_41_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_42_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_43_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_44_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_45_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_46_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_47_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_48_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_49_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_50_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_51_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_52_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_53_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_54_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_55_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_56_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_57_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_58_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/great_expectations_mfs_0812_librivox_64kb_mp3/greatexpectations_59_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_01_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_04_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_05_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_07_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_10_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_11_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_13_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_14_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_15_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_20_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/mp3Audio/Dickens/hard_times_dickens_0709_librivox_64kb_mp3/hardtimes_21_dickens_64kb.mp3\n",
      "scientist.48.book.on.tape/transcribe/\n",
      "scientist.48.book.on.tape/transcribe/output/\n",
      "scientist.48.book.on.tape/transcribe/output/austen/\n",
      "scientist.48.book.on.tape/transcribe/output/austen/AutenAsrOutput.json\n",
      "scientist.48.book.on.tape/transcribe/output/dickens/\n",
      "scientist.48.book.on.tape/transcribe/output/dickens/DisckensAsrOutput.json\n"
     ]
    }
   ],
   "source": [
    "import boto3, os\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "for obj in s3.Bucket(name='scientist.48.book.on.tape').objects.all():\n",
    "    print(os.path.join(obj.bucket_name, obj.key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the transcribe JSON from S3, convert to CSV per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the CSV and break down by sentence per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will print the labels file (authors.txt) to see all possible labels followed by creating an index to label mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane Austen\n",
      "Charles Dickens"
     ]
    }
   ],
   "source": [
    "!cat authors.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates the mapping from integer indices to class label which will later be used to retrieve the actual class name during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'Jane Austen', '2': 'Charles Dickens'}\n"
     ]
    }
   ],
   "source": [
    "index_to_label = {} \n",
    "with open(\"authors.txt\") as f:\n",
    "    for i,label in enumerate(f.readlines()):\n",
    "        index_to_label[str(i+1)] = label.strip()\n",
    "print(index_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to preprocess the training data into space separated tokenized text format which can be consumed by BlazingText algorithm. Also, as mentioned previously, the class label(s) should be prefixed with __label__ and it should be present in the same line along with the original sentence. We'll use nltk library to tokenize the input sentences from DBPedia dataset.\n",
    "\n",
    "Download the nltk tokenizer and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Method transform_instance(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_instance(row):\n",
    "    cur_row = []\n",
    "    label = \"__label__\" + index_to_label[row[0]]  #Prefix the index-ed label with __label__\n",
    "    cur_row.append(label)\n",
    "    cur_row.extend(nltk.word_tokenize(row[1].lower()))\n",
    "    cur_row.extend(nltk.word_tokenize(row[2].lower()))\n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform_instance will be applied to each data instance in parallel using python's multiprocessing module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Method preprocess(input, output, keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_file, output_file, keep=1):\n",
    "    all_rows = []\n",
    "    with open(input_file, 'r') as csvinfile:\n",
    "        csv_reader = csv.reader(csvinfile, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            all_rows.append(row)\n",
    "    shuffle(all_rows)\n",
    "    all_rows = all_rows[:int(keep*len(all_rows))]\n",
    "    pool = Pool(processes=multiprocessing.cpu_count())\n",
    "    transformed_rows = pool.map(transform_instance, all_rows)\n",
    "    pool.close() \n",
    "    pool.join()\n",
    "    \n",
    "    with open(output_file, 'w') as csvoutfile:\n",
    "        csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n')\n",
    "        csv_writer.writerows(transformed_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now that we are done with all the setup that is needed, we are ready to train our object detector. To begin, let us create a sageMaker.estimator.Estimator object. This estimator will launch the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 811284229777.dkr.ecr.us-east-1.amazonaws.com/blazingtext:latest (us-east-1)\n"
     ]
    }
   ],
   "source": [
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print('Using SageMaker BlazingText container: {} ({})'.format(container, region_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting / Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop / Close the Endpoint (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
